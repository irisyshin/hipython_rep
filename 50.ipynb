{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00eb6ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (2.32.4)\n",
      "Requirement already satisfied: requests_file in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: selenium in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (4.34.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: lxml in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (6.0.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (11.3.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (6.29.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from requests) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from requests) (2025.7.14)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Requirement already satisfied: trio~=0.30.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from selenium) (0.30.0)\n",
      "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (1.8.15)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (8.37.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (5.8.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (1.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (27.0.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (6.5.1)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipykernel) (5.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.4.6)\n",
      "Requirement already satisfied: decorator in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (5.2.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (2.19.2)\n",
      "Requirement already satisfied: stack_data in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from ipython>=7.23.1->ipykernel) (0.6.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (4.3.8)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel) (311)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in c:\\users\\admin\\miniconda3\\envs\\webcrawl_env\\lib\\site-packages (from stack_data->ipython>=7.23.1->ipykernel) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests requests_file beautifulsoup4 selenium pandas lxml pillow ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d42beea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "109e4f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\githome\\hipython_rep\n",
      "c:\\githome\\hipython_rep\\html\\sample.html\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(os.getcwd())\n",
    "print(os.path.abspath('html/sample.html')) #path 정확하게 지정하는게 필요함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08aae7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" con\n"
     ]
    }
   ],
   "source": [
    "# 파일의 절대경로 \n",
    "abspath = os.path.abspath('html/sample.html')\n",
    "\n",
    "urlpath = \"file:///\"+abspath\n",
    "\n",
    "with urllib.request.urlopen(urlpath) as f: \n",
    "    html = f.read().decode('utf-8')\n",
    "    \n",
    "print(html[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3373e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('http://localhost:5500/html/sample.html')\n",
    "# 200 완료 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8126a5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
      "    <title>Hello LGU+ SWBootCamp</title>\n",
      "</head>\n",
      "<body>\n",
      "    <h1>Hello scrapping</h1>\n",
      "    <div id=\"subject\">선택자</div>\n",
      "    <div class=\"contents\">\n",
      "        선택자가 중요합니다. 잘 찾아주세요.\n",
      "        <span>다른 <b>요소가 나올 수도 </b> 있습니다.</span>\n",
      "    </div>\n",
      "    <div>CSS 선택자에는 요소 선택자, 클래스 선택자, ID 선택자가 있습니다.</div>\n",
      "<!-- Code injected by live-server -->\n",
      "<script>\n",
      "\t// <![CDATA[  <-- For SVG support\n",
      "\tif ('WebSocket' in window) {\n",
      "\t\t(function () {\n",
      "\t\t\tfunction refreshCSS() {\n",
      "\t\t\t\tvar sheets = [].slice.call(document.getElementsByTagName(\"link\"));\n",
      "\t\t\t\tvar head = document.getElementsByTagName(\"head\")[0];\n",
      "\t\t\t\tfor (var i = 0; i < sheets.length; ++i) {\n",
      "\t\t\t\t\tvar elem = sheets[i];\n",
      "\t\t\t\t\tvar parent = elem.parentElement || head;\n",
      "\t\t\t\t\tparent.removeChild(elem);\n",
      "\t\t\t\t\tvar rel = elem.rel;\n",
      "\t\t\t\t\tif (elem.href && typeof rel != \"string\" || rel.length == 0 || rel.toLowerCase() == \"stylesheet\") {\n",
      "\t\t\t\t\t\tvar url = elem.href.replace(/(&|\\?)_cacheOverride=\\d+/, '');\n",
      "\t\t\t\t\t\telem.href = url + (url.indexOf('?') >= 0 ? '&' : '?') + '_cacheOverride=' + (new Date().valueOf());\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tparent.appendChild(elem);\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tvar protocol = window.location.protocol === 'http:' ? 'ws://' : 'wss://';\n",
      "\t\t\tvar address = protocol + window.location.host + window.location.pathname + '/ws';\n",
      "\t\t\tvar socket = new WebSocket(address);\n",
      "\t\t\tsocket.onmessage = function (msg) {\n",
      "\t\t\t\tif (msg.data == 'reload') window.location.reload();\n",
      "\t\t\t\telse if (msg.data == 'refreshcss') refreshCSS();\n",
      "\t\t\t};\n",
      "\t\t\tif (sessionStorage && !sessionStorage.getItem('IsThisFirstTime_Log_From_LiveServer')) {\n",
      "\t\t\t\tconsole.log('Live reload enabled.');\n",
      "\t\t\t\tsessionStorage.setItem('IsThisFirstTime_Log_From_LiveServer', true);\n",
      "\t\t\t}\n",
      "\t\t})();\n",
      "\t}\n",
      "\telse {\n",
      "\t\tconsole.error('Upgrade your browser. This Browser is NOT supported WebSocket for Live-Reloading.');\n",
      "\t}\n",
      "\t// ]]>\n",
      "</script>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://localhost:5500/html/sample.html')\n",
    "print(res.status_code)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d54ec900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<!DOCTYPE html>\n",
       "\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "<meta charset=\"utf-8\"/>\n",
       "<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
       "<title>Hello LGU+ SWBootCamp</title>\n",
       "</head>\n",
       "<body>\n",
       "<h1>Hello scrapping</h1>\n",
       "<div id=\"subject\">선택자</div>\n",
       "<div class=\"contents\">\n",
       "        선택자가 중요합니다. 잘 찾아주세요.\n",
       "        <span>다른 <b>요소가 나올 수도 </b> 있습니다.</span>\n",
       "</div>\n",
       "<div>CSS 선택자에는 요소 선택자, 클래스 선택자, ID 선택자가 있습니다.</div>\n",
       "<!-- Code injected by live-server -->\n",
       "<script>\n",
       "\t// <![CDATA[  <-- For SVG support\n",
       "\tif ('WebSocket' in window) {\n",
       "\t\t(function () {\n",
       "\t\t\tfunction refreshCSS() {\n",
       "\t\t\t\tvar sheets = [].slice.call(document.getElementsByTagName(\"link\"));\n",
       "\t\t\t\tvar head = document.getElementsByTagName(\"head\")[0];\n",
       "\t\t\t\tfor (var i = 0; i < sheets.length; ++i) {\n",
       "\t\t\t\t\tvar elem = sheets[i];\n",
       "\t\t\t\t\tvar parent = elem.parentElement || head;\n",
       "\t\t\t\t\tparent.removeChild(elem);\n",
       "\t\t\t\t\tvar rel = elem.rel;\n",
       "\t\t\t\t\tif (elem.href && typeof rel != \"string\" || rel.length == 0 || rel.toLowerCase() == \"stylesheet\") {\n",
       "\t\t\t\t\t\tvar url = elem.href.replace(/(&|\\?)_cacheOverride=\\d+/, '');\n",
       "\t\t\t\t\t\telem.href = url + (url.indexOf('?') >= 0 ? '&' : '?') + '_cacheOverride=' + (new Date().valueOf());\n",
       "\t\t\t\t\t}\n",
       "\t\t\t\t\tparent.appendChild(elem);\n",
       "\t\t\t\t}\n",
       "\t\t\t}\n",
       "\t\t\tvar protocol = window.location.protocol === 'http:' ? 'ws://' : 'wss://';\n",
       "\t\t\tvar address = protocol + window.location.host + window.location.pathname + '/ws';\n",
       "\t\t\tvar socket = new WebSocket(address);\n",
       "\t\t\tsocket.onmessage = function (msg) {\n",
       "\t\t\t\tif (msg.data == 'reload') window.location.reload();\n",
       "\t\t\t\telse if (msg.data == 'refreshcss') refreshCSS();\n",
       "\t\t\t};\n",
       "\t\t\tif (sessionStorage && !sessionStorage.getItem('IsThisFirstTime_Log_From_LiveServer')) {\n",
       "\t\t\t\tconsole.log('Live reload enabled.');\n",
       "\t\t\t\tsessionStorage.setItem('IsThisFirstTime_Log_From_LiveServer', true);\n",
       "\t\t\t}\n",
       "\t\t})();\n",
       "\t}\n",
       "\telse {\n",
       "\t\tconsole.error('Upgrade your browser. This Browser is NOT supported WebSocket for Live-Reloading.');\n",
       "\t}\n",
       "\t// ]]>\n",
       "</script>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5f81fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"subject\">선택자</div>,\n",
       " <div class=\"contents\">\n",
       "         선택자가 중요합니다. 잘 찾아주세요.\n",
       "         <span>다른 <b>요소가 나올 수도 </b> 있습니다.</span>\n",
       " </div>,\n",
       " <div>CSS 선택자에는 요소 선택자, 클래스 선택자, ID 선택자가 있습니다.</div>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div', class_='contents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16df8e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"subject\">선택자</div>,\n",
       " <div class=\"contents\">\n",
       "         선택자가 중요합니다. 잘 찾아주세요.\n",
       "         <span>다른 <b>요소가 나올 수도 </b> 있습니다.</span>\n",
       " </div>,\n",
       " <div>CSS 선택자에는 요소 선택자, 클래스 선택자, ID 선택자가 있습니다.</div>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div', id='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94da947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"contents\">\n",
       "         선택자가 중요합니다. 잘 찾아주세요.\n",
       "         <span>다른 <b>요소가 나올 수도 </b> 있습니다.</span>\n",
       " </div>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('div.contents') # class 선책자., id 선택자 # 이렇게 해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b21c4398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div id=\"subject\">선택자</div>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"#subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0186239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select(\"div.h1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "093ba0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div id=\"subject\">선택자</div>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select_one('div')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db14e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 환율 정보 가져오기\n",
    "url = \"https://finance.naver.com/marketindex/\"\n",
    "m_index = requests.get(url)\n",
    "m_index.encoding = 'euc-kr'    # 인코딩을 명시적으로 설정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d32b5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,379.30\n"
     ]
    }
   ],
   "source": [
    "if m_index.status_code == 200:\n",
    "    soup = BeautifulSoup(m_index.content, 'html.parser') # 페이지 전체\n",
    "    price = soup.select_one('span.value') #span 태그 목록중에서 1번쨰\n",
    "    print(price.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "66fcc82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЙЬБЙ USD : 1,379.30\n",
      "РЯКЛ JPY(100ПЃ) : 936.23\n",
      "РЏЗДПЌЧе EUR : 1,621.44\n",
      "СпБЙ CNY : 192.44\n",
      "ДоЗЏ/РЯКЛ ПЃ : 146.7900\n",
      "РЏЗЮ/ДоЗЏ : 1.1765\n",
      "ПЕБЙ ЦФПюЕх/ДоЗЏ : 1.3540\n",
      "ДоЗЏРЮЕІНК : 97.1200\n",
      "WTI : 66.03\n",
      "ШжЙпРЏ : 1667.38\n",
      "БЙСІ Бн : 3373.5\n",
      "БЙГЛ Бн : 148801.78\n"
     ]
    }
   ],
   "source": [
    "# 환율 항목들 모두 선택\n",
    "currency_items = soup.select(\"ul.data_lst li\")\n",
    "\n",
    "\n",
    "result = {}                     # 결과 저장용 딕셔너리\n",
    "\n",
    "\n",
    "for item in currency_items:     # 각 환율 항목 순회\n",
    "    name_tag = item.select_one(\"h3.h_lst\")\n",
    "    country_tag = name_tag.get_text(strip=True)\n",
    "    value_tag = item.select_one(\"span.value\")\n",
    "    if country_tag and value_tag:\n",
    "        result[country_tag] = value_tag.get_text(strip=True)\n",
    "\n",
    "# 출력\n",
    "for code, rate in result.items():\n",
    "    print(f\"{code} : {rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "89ff926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span class=\"value\">1,378.50</span>, <span class=\"value\">937.53</span>, <span class=\"value\">1,619.88</span>, <span class=\"value\">192.46</span>, <span class=\"value\">146.7900</span>, <span class=\"value\">1.1765</span>, <span class=\"value\">1.3540</span>, <span class=\"value\">97.1200</span>, <span class=\"value\">66.03</span>, <span class=\"value\">1667.38</span>, <span class=\"value\">3373.5</span>, <span class=\"value\">148797.85</span>]\n"
     ]
    }
   ],
   "source": [
    "if m_index.status_code == 200:\n",
    "    soup = BeautifulSoup(m_index.content, 'html.parser') # 페이지 전체\n",
    "    price = soup.select('span.value') #span 태그 목록중에서 1번쨰\n",
    "    print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exchangeList > li.on > a.head.usd > div > span.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exchangeList > li.on > a.head.jpy > div > span.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "349c6a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,378.50\n"
     ]
    }
   ],
   "source": [
    "if m_index.status_code == 200:\n",
    "    soup = BeautifulSoup(m_index.content, 'html.parser') # 페이지 전체\n",
    "    #price = soup.select('span.value') #span 태그 목록중에서 1번쨰\n",
    "    us_price = soup.select_one('a.head.usd > div > span.value')\n",
    "    print(us_price.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ff07395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "937.53\n"
     ]
    }
   ],
   "source": [
    "if m_index.status_code == 200:\n",
    "    soup = BeautifulSoup(m_index.content, 'html.parser') # 페이지 전체\n",
    "    #price = soup.select('span.value') #span 태그 목록중에서 1번쨰\n",
    "    jpy_price = soup.select_one('a.head.jpy > div > span.value')\n",
    "    print(jpy_price.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e3aa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# style tag. content tag 꺼내기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1050f9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <head>\n",
      "    <meta charset=\"UTF-8\" />\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "    <title>문서의 제목</title>\n",
      "    <link rel=\"styleshee\" href=\"default.css\" />\n",
      "    <style type=\"text/css\">\n",
      "      /* css 스타일 지정 */\n",
      "    </style>\n",
      "    <script type=\"text/javascript\">\n",
      "      //자바스크립트 코드\n",
      "    </script>\n",
      "  </head>\n",
      "  <body>\n",
      "    <!-- 주석 -->\n",
      "    본문의 내용...\n",
      "  <!-- Code injected by live-server -->\n",
      "<script>\n",
      "\t// <![CDATA[  <-- For SVG support\n",
      "\tif ('WebSocket' in window) {\n",
      "\t\t(function () {\n",
      "\t\t\tfunction refreshCSS() {\n",
      "\t\t\t\tvar sheets = [].slice.call(document.getElementsByTagName(\"link\"));\n",
      "\t\t\t\tvar head = document.getElementsByTagName(\"head\")[0];\n",
      "\t\t\t\tfor (var i = 0; i < sheets.length; ++i) {\n",
      "\t\t\t\t\tvar elem = sheets[i];\n",
      "\t\t\t\t\tvar parent = elem.parentElement || head;\n",
      "\t\t\t\t\tparent.removeChild(elem);\n",
      "\t\t\t\t\tvar rel = elem.rel;\n",
      "\t\t\t\t\tif (elem.href && typeof rel != \"string\" || rel.length == 0 || rel.toLowerCase() == \"stylesheet\") {\n",
      "\t\t\t\t\t\tvar url = elem.href.replace(/(&|\\?)_cacheOverride=\\d+/, '');\n",
      "\t\t\t\t\t\telem.href = url + (url.indexOf('?') >= 0 ? '&' : '?') + '_cacheOverride=' + (new Date().valueOf());\n",
      "\t\t\t\t\t}\n",
      "\t\t\t\t\tparent.appendChild(elem);\n",
      "\t\t\t\t}\n",
      "\t\t\t}\n",
      "\t\t\tvar protocol = window.location.protocol === 'http:' ? 'ws://' : 'wss://';\n",
      "\t\t\tvar address = protocol + window.location.host + window.location.pathname + '/ws';\n",
      "\t\t\tvar socket = new WebSocket(address);\n",
      "\t\t\tsocket.onmessage = function (msg) {\n",
      "\t\t\t\tif (msg.data == 'reload') window.location.reload();\n",
      "\t\t\t\telse if (msg.data == 'refreshcss') refreshCSS();\n",
      "\t\t\t};\n",
      "\t\t\tif (sessionStorage && !sessionStorage.getItem('IsThisFirstTime_Log_From_LiveServer')) {\n",
      "\t\t\t\tconsole.log('Live reload enabled.');\n",
      "\t\t\t\tsessionStorage.setItem('IsThisFirstTime_Log_From_LiveServer', true);\n",
      "\t\t\t}\n",
      "\t\t})();\n",
      "\t}\n",
      "\telse {\n",
      "\t\tconsole.error('Upgrade your browser. This Browser is NOT supported WebSocket for Live-Reloading.');\n",
      "\t}\n",
      "\t// ]]>\n",
      "</script>\n",
      "</body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('http://localhost:5500/html/basic.html')\n",
    "print(res.status_code)\n",
    "print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4140d998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      /* css 스타일 지정 */\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "if m_index.status_code == 200:\n",
    "    soup = BeautifulSoup(res.content, 'html.parser') # 페이지 전체\n",
    "    #price = soup.select('span.value') #span 태그 목록중에서 1번쨰\n",
    "    style_tag = soup.select_one('head > style')\n",
    "    print(style_tag.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff4a6de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 USD : 1,379.30\n",
      "일본 JPY(100엔) : 936.23\n",
      "유럽연합 EUR : 1,621.44\n",
      "중국 CNY : 192.44\n",
      "달러/일본 엔 : 146.7900\n",
      "유로/달러 : 1.1765\n",
      "영국 파운드/달러 : 1.3540\n",
      "달러인덱스 : 97.1200\n",
      "WTI : 66.03\n",
      "휘발유 : 1667.38\n",
      "국제 금 : 3373.5\n",
      "국내 금 : 148801.78\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 네이버 환율 페이지 URL\n",
    "url = 'https://finance.naver.com/marketindex/'\n",
    "\n",
    "# 웹 페이지 가져오기\n",
    "response = requests.get(url)\n",
    "response.encoding = 'euc-kr'    # 인코딩을 명시적으로 설정\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# 환율 항목들 모두 선택\n",
    "currency_items = soup.select(\"ul.data_lst li\")\n",
    "\n",
    "\n",
    "result = {}                     # 결과 저장용 딕셔너리\n",
    "\n",
    "\n",
    "for item in currency_items:     # 각 환율 항목 순회\n",
    "    name_tag = item.select_one(\"h3.h_lst\")\n",
    "    country_tag = name_tag.get_text(strip=True)\n",
    "    value_tag = item.select_one(\"span.value\")\n",
    "    if country_tag and value_tag:\n",
    "        result[country_tag] = value_tag.get_text(strip=True)\n",
    "\n",
    "# 출력\n",
    "for code, rate in result.items():\n",
    "    print(f\"{code} : {rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e4f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webcrawl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
